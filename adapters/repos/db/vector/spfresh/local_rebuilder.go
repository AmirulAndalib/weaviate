package spfresh

import (
	"context"
	"sync"

	"github.com/pkg/errors"
	"github.com/sirupsen/logrus"
	"github.com/weaviate/weaviate/adapters/repos/db/vector/common"
)

type BackgroundOpType string

const (
	BackgroundOpSplit    BackgroundOpType = "split"
	BackgroundOpMerge    BackgroundOpType = "merge"
	BackgroundOpReassign BackgroundOpType = "reassign"
)

type Operation struct {
	PostingID uint64
	OpType    BackgroundOpType
}

// LocalRebuilder manages background operations for postings in the SPFresh index.
// It handles split, merge, and reassign requests generated by insertions or during search
// operations. It uses a worker pool to process these operations concurrently.
type LocalRebuilder struct {
	UserConfig *UserConfig      // UserConfig contains user-defined settings for the rebuilder.
	SPTAG      SPTAG            // SPTAG provides access to the SPTAG index for centroid operations.
	Store      *BlockController // Used for managing persistence of postings.
	Logger     *logrus.Entry    // Logger for logging operations and errors.
	Splitter   PostingSplitter  // Used for splitting postings into two.
	VersionMap *VersionMap      // VersionMap provides access to vector versions.
	IDs        *common.MonotonicCounter[uint64]

	ch     chan Operation
	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup

	dedup deduplicator // Deduplicator to prevent multiple operations on the same posting
}

func (r *LocalRebuilder) Start(ctx context.Context) {
	if r.UserConfig == nil {
		panic("UserConfig must be set before starting LocalRebuilder")
	}
	if r.Store == nil {
		panic("Store must be set before starting LocalRebuilder")
	}
	if r.Splitter == nil {
		panic("Splitter must be set before starting LocalRebuilder")
	}
	if r.VersionMap == nil {
		panic("VersionMap must be set before starting LocalRebuilder")
	}
	if r.IDs == nil {
		panic("IdGenerator must be set before starting LocalRebuilder")
	}

	r.ch = make(chan Operation, r.UserConfig.Workers)
	r.ctx, r.cancel = context.WithCancel(context.Background())

	if r.Logger == nil {
		r.Logger = logrus.New().WithField("component", "LocalRebuilder")
	} else {
		r.Logger = r.Logger.WithField("component", "LocalRebuilder")
	}

	for i := 0; i < r.UserConfig.Workers; i++ {
		r.wg.Add(1)
		go r.worker()
	}
}

func (r *LocalRebuilder) Enqueue(ctx context.Context, op Operation) error {
	if r.ctx == nil {
		return nil // Not started yet
	}

	if r.ctx.Err() != nil {
		return r.ctx.Err() // Context already cancelled
	}

	// Check if the operation is already in progress
	if !r.dedup.tryEnqueue(op) {
		r.Logger.WithField("postingID", op.PostingID).
			WithField("operation", op.OpType).
			Debug("Operation already in progress, skipping enqueue")
		return nil
	}

	// Enqueue the operation to the channel
	select {
	case r.ch <- op:
	case <-ctx.Done():
		return ctx.Err()
	}

	return nil
}

func (r *LocalRebuilder) worker() {
	defer r.wg.Done()

	var err error

	for op := range r.ch {
		if r.ctx.Err() != nil {
			return // Stop processing if context is cancelled
		}

		// Process the operation
		switch op.OpType {
		case BackgroundOpSplit:
			// Handle split operation
			err = r.doSplit(op)
		case BackgroundOpMerge:
			// Handle merge operation
		case BackgroundOpReassign:
			// Handle reassign operation
		default:
			r.Logger.Warnf("Unknown operation type: %s for posting ID: %d", op.OpType, op.PostingID)
		}

		if err != nil {
			r.Logger.WithError(err).
				WithField("postingID", op.PostingID).
				WithField("operation", op.OpType).
				Error("Failed to process operation")
			continue // Log the error and continue processing other operations
		}
	}
}

func (r *LocalRebuilder) Close(ctx context.Context) error {
	if r.ctx == nil {
		return nil // Already closed or not started
	}

	if r.ctx.Err() != nil {
		return r.ctx.Err() // Context already cancelled
	}

	// Cancel the context to prevent new operations from being enqueued
	r.cancel()

	// Close the channel to signal workers to stop
	close(r.ch)

	r.wg.Wait() // Wait for all workers to finish
	return nil
}

func (r *LocalRebuilder) doSplit(op Operation) error {
	defer r.dedup.done(op) // Ensure we mark the operation as done

	// TODO: Use WAL

	p, err := r.Store.Get(r.ctx, op.PostingID)
	if err != nil {
		return err
	}

	// skip if the posting is too small
	if len(p) < r.UserConfig.MaxPostingSize {
		r.Logger.
			WithField("postingID", op.PostingID).
			WithField("size", len(p)).
			WithField("max", r.UserConfig.MaxPostingSize).
			Debug("Posting is too small, skipping split operation")
		return nil
	}

	// garbage collect the deleted vectors
	filtered := p.GarbageCollect(r.VersionMap)

	// skip if the filtered posting is now too small
	if len(filtered) < r.UserConfig.MaxPostingSize {
		r.Logger.
			WithField("postingID", op.PostingID).
			WithField("size", len(filtered)).
			WithField("max", r.UserConfig.MaxPostingSize).
			Debug("Posting has less than max size after garbage collection, skipping split operation")

		// persist the filtered posting
		err = r.Store.Put(r.ctx, op.PostingID, filtered)
		if err != nil {
			return errors.Wrapf(err, "failed to put filtered posting %d after split operation", op.PostingID)
		}

		return nil
	}

	// split the vectors into two clusters
	result, err := r.Splitter.Split(filtered)
	if err != nil {
		return errors.Wrapf(err, "failed to split vectors for posting %d", op.PostingID)
	}

	// persist the new postings first
	leftID, rightID := r.IDs.NextN(2)
	err = r.Store.Put(r.ctx, leftID, result.LeftPosting)
	if err != nil {
		return errors.Wrapf(err, "failed to put left posting %d for split operation on posting %d", leftID, op.PostingID)
	}
	err = r.Store.Put(r.ctx, rightID, result.RightPosting)
	if err != nil {
		// TODO: cleanup?
		return errors.Wrapf(err, "failed to put right posting %d for split operation on posting %d", rightID, op.PostingID)
	}

	// atomically add new centroids to the SPTAG index and delete the old one
	err = r.SPTAG.Split(op.PostingID, leftID, rightID, result.LeftCentroid, result.RightCentroid)
	if err != nil {
		return errors.Wrapf(err, "failed to split centroid for posting %d into %d and %d", op.PostingID, leftID, rightID)
	}

	// TODO: add reassign logic

	return nil
}

// deduplicator ensures only one operation per posting ID can be enqueued at a time.
type deduplicator struct {
	mu       sync.Mutex
	inflight map[Operation]struct{} // map of inflight operations by posting ID
}

func (d *deduplicator) tryEnqueue(op Operation) bool {
	d.mu.Lock()
	defer d.mu.Unlock()

	if d.inflight == nil {
		d.inflight = make(map[Operation]struct{})
		d.inflight[op] = struct{}{}
		return true // First operation, no duplicates
	}

	if _, exists := d.inflight[op]; exists {
		return false // Operation already in progress
	}

	d.inflight[op] = struct{}{}
	return true
}

func (d *deduplicator) done(op Operation) {
	d.mu.Lock()
	defer d.mu.Unlock()

	delete(d.inflight, op)
}
